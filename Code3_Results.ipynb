{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648319aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Class responsible for processing anomaly scores\n",
    "class AnomalyScoreProcessor:\n",
    "    # Initialization method that loads the data and sets the output files\n",
    "    def __init__(self, input_file, output_key_file, output_value_file):\n",
    "        # Reads the input CSV file and stores it in a dataframe (self.data)\n",
    "        self.data = pd.read_csv(input_file, sep=';')\n",
    "        # Stores the paths for the output key and value files\n",
    "        self.output_key_file = output_key_file\n",
    "        self.output_value_file = output_value_file\n",
    "\n",
    "    # Private method to create a dataframe from a specific score column\n",
    "    def _create_score_df(self, score_col, label):\n",
    "        # Create a dataframe with 'id' and the score column ('score_col')\n",
    "        df = pd.DataFrame({\n",
    "            'id': self.data['id'],\n",
    "            'pontuacao': self.data[score_col]\n",
    "        }).sort_values(by='pontuacao', ascending=False)  # Sort the data by score in descending order\n",
    "        \n",
    "        # Create a key dataframe that contains a list of IDs, sorted by score, with the column name as 'label'\n",
    "        df_key = pd.DataFrame({label: df['id'].tolist()})\n",
    "        \n",
    "        # Create a value dataframe that contains 'id' and their respective scores, labeled with 'label'\n",
    "        df_valor = pd.DataFrame({\n",
    "            'id': self.data['id'],\n",
    "            label: self.data[score_col]\n",
    "        })\n",
    "        # Return both the key and value dataframes\n",
    "        return df_key, df_valor\n",
    "\n",
    "    # Private method to create dataframes with anomaly predictions and anomaly scores\n",
    "    def _create_anomaly_df(self, pred_col, score_col, label):\n",
    "        # Create a dataframe with 'id', prediction column ('pred_col'), and score column ('score_col')\n",
    "        df = pd.DataFrame({\n",
    "            'id': self.data['id'],\n",
    "            'predicao': self.data[pred_col],\n",
    "            'pontuacao': self.data[score_col]\n",
    "        }).sort_values(['predicao', 'pontuacao'])  # Sort by prediction and score\n",
    "        \n",
    "        # Create a new column 'y_pred', where anomaly (-1) is mapped to 1, and normal (1) to 0\n",
    "        df['y_pred'] = np.where(df['predicao'] == -1, 1, 0)\n",
    "        \n",
    "        # Assign a rank to each row (descending order) based on the index position\n",
    "        df['scores'] = range(len(df), 0, -1)\n",
    "        \n",
    "        # Normalize the scores by dividing them by the maximum score\n",
    "        df['score'] = df['scores'] / np.max(df['scores'])\n",
    "        \n",
    "        # Create a value dataframe containing 'id' and the normalized score, labeled as 'label'\n",
    "        df_valor = pd.DataFrame({\n",
    "            'id': self.data['id'],\n",
    "            label: df['score']\n",
    "        })\n",
    "        \n",
    "        # Create a key dataframe with the IDs sorted by score, labeled as 'label'\n",
    "        df_key = pd.DataFrame({label: df['id'].tolist()})\n",
    "        \n",
    "        # Return both the key and value dataframes\n",
    "        return df_key, df_valor\n",
    "\n",
    "    # Method to process and combine different anomaly scores and predictions\n",
    "    def process_scores(self):\n",
    "        # Create score dataframes for OS1 and OS2 columns\n",
    "        df_key, df_valor = self._create_score_df('OS1', 'OS1')\n",
    "        df_key2, df_valor2 = self._create_score_df('OS2', 'OS2')\n",
    "        \n",
    "        # Join OS1 and OS2 dataframes (keys and values)\n",
    "        df_key = df_key.join(df_key2, how='outer')\n",
    "        df_valor = df_valor.join(df_valor2.set_index('id'), on='id', rsuffix='_OS2')\n",
    "\n",
    "        # Dictionary of anomaly models with their respective prediction and score column names\n",
    "        anomaly_models = {\n",
    "            'IsF': ('anomaly-IsF', 'scores-IsF'),\n",
    "            'LOF': ('anomaly-Lof', 'scores-Lof'),\n",
    "            'COV': ('anomaly-Cov', 'scores-Cov'),\n",
    "            'SVM': ('anomaly-SVM', 'scores-SVM')\n",
    "        }\n",
    "        \n",
    "        # Iterate through each anomaly model, process it, and join the results to the main dataframe\n",
    "        for label, (pred_col, score_col) in anomaly_models.items():\n",
    "            df_key_anomaly, df_valor_anomaly = self._create_anomaly_df(pred_col, score_col, label)\n",
    "            df_key = df_key.join(df_key_anomaly, how='outer')\n",
    "            df_valor = df_valor.join(df_valor_anomaly.set_index('id'), on='id', rsuffix=f'_{label}')\n",
    "\n",
    "        # Save the resulting key and value dataframes to CSV files\n",
    "        df_key.to_csv(self.output_key_file, sep=';', index=False)\n",
    "        df_valor.to_csv(self.output_value_file, sep=';', index=False)\n",
    "\n",
    "# Main method to run the program\n",
    "def main():\n",
    "    # Create processor for human capital data, process it, and save results\n",
    "    processor = AnomalyScoreProcessor('data/humanNet.csv', 'data/key_human.csv', 'data/value_human.csv')\n",
    "    processor.process_scores()\n",
    "\n",
    "    # Create processor for social capital data, process it, and save results\n",
    "    processor = AnomalyScoreProcessor('data/socialNet.csv', 'data/key_social.csv', 'data/value_social.csv')\n",
    "    processor.process_scores()\n",
    "\n",
    "    # Create processor for mixed capital data, process it, and save results\n",
    "    processor = AnomalyScoreProcessor('data/mixedNet.csv', 'data/key_mixed.csv', 'data/value_mixed.csv')\n",
    "    processor.process_scores()\n",
    "    \n",
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # If so, run the main function\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

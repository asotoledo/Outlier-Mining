{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648319aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Class responsible for processing anomaly scores\n",
    "class AnomalyScoreProcessor:\n",
    "    # Initialization method that loads the data and sets the output files\n",
    "    def __init__(self, input_file, output_key_file, output_value_file):\n",
    "        # Reads the input CSV file and stores it in a dataframe (self.data)\n",
    "        self.data = pd.read_csv(input_file, sep=';')\n",
    "        # Stores the paths for the output key and value files\n",
    "        self.output_key_file = output_key_file\n",
    "        self.output_value_file = output_value_file\n",
    "\n",
    "    # Private method to create a dataframe from a specific score column\n",
    "    def _create_score_df(self, score_col, label):\n",
    "        # Create a dataframe with 'id' and the score column ('score_col')\n",
    "        df = pd.DataFrame({\n",
    "            'id': self.data['id'],\n",
    "            'pontuacao': self.data[score_col]\n",
    "        }).sort_values(by='pontuacao', ascending=False)  # Sort the data by score in descending order\n",
    "        \n",
    "        # Create a key dataframe that contains a list of IDs, sorted by score, with the column name as 'label'\n",
    "        df_key = pd.DataFrame({label: df['id'].tolist()})\n",
    "        \n",
    "        # Create a value dataframe that contains 'id' and their respective scores, labeled with 'label'\n",
    "        df_valor = pd.DataFrame({\n",
    "            'id': self.data['id'],\n",
    "            label: self.data[score_col]\n",
    "        })\n",
    "        # Return both the key and value dataframes\n",
    "        return df_key, df_valor\n",
    "\n",
    "    # Private method to create dataframes with anomaly predictions and anomaly scores\n",
    "    def _create_anomaly_df(self, pred_col, score_col, label):\n",
    "        # Create a dataframe with 'id', prediction column ('pred_col'), and score column ('score_col')\n",
    "        df = pd.DataFrame({\n",
    "            'id': self.data['id'],\n",
    "            'predicao': self.data[pred_col],\n",
    "            'pontuacao': self.data[score_col]\n",
    "        }).sort_values(['predicao', 'pontuacao'])  # Sort by prediction and score\n",
    "        \n",
    "        # Create a new column 'y_pred', where anomaly (-1) is mapped to 1, and normal (1) to 0\n",
    "        df['y_pred'] = np.where(df['predicao'] == -1, 1, 0)\n",
    "        \n",
    "        # Assign a rank to each row (descending order) based on the index position\n",
    "        df['scores'] = range(len(df), 0, -1)\n",
    "        \n",
    "        # Normalize the scores by dividing them by the maximum score\n",
    "        df['score'] = df['scores'] / np.max(df['scores'])\n",
    "        \n",
    "        # Create a value dataframe containing 'id' and the normalized score, labeled as 'label'\n",
    "        df_valor = pd.DataFrame({\n",
    "            'id': self.data['id'],\n",
    "            label: df['score']\n",
    "        })\n",
    "        \n",
    "        # Create a key dataframe with the IDs sorted by score, labeled as 'label'\n",
    "        df_key = pd.DataFrame({label: df['id'].tolist()})\n",
    "        \n",
    "        # Return both the key and value dataframes\n",
    "        return df_key, df_valor\n",
    "\n",
    "    # Method to process and combine different anomaly scores and predictions\n",
    "    def process_scores(self):\n",
    "        # Create score dataframes for OS1 and OS2 columns\n",
    "        df_key, df_valor = self._create_score_df('OS1', 'OS1')\n",
    "        df_key2, df_valor2 = self._create_score_df('OS2', 'OS2')\n",
    "        \n",
    "        # Join OS1 and OS2 dataframes (keys and values)\n",
    "        df_key = df_key.join(df_key2, how='outer')\n",
    "        df_valor = df_valor.join(df_valor2.set_index('id'), on='id', rsuffix='_OS2')\n",
    "\n",
    "        # Dictionary of anomaly models with their respective prediction and score column names\n",
    "        anomaly_models = {\n",
    "            'IsF': ('anomaly-IsF', 'scores-IsF'),\n",
    "            'LOF': ('anomaly-Lof', 'scores-Lof'),\n",
    "            'COV': ('anomaly-Cov', 'scores-Cov'),\n",
    "            'SVM': ('anomaly-SVM', 'scores-SVM')\n",
    "        }\n",
    "        \n",
    "        # Iterate through each anomaly model, process it, and join the results to the main dataframe\n",
    "        for label, (pred_col, score_col) in anomaly_models.items():\n",
    "            df_key_anomaly, df_valor_anomaly = self._create_anomaly_df(pred_col, score_col, label)\n",
    "            df_key = df_key.join(df_key_anomaly, how='outer')\n",
    "            df_valor = df_valor.join(df_valor_anomaly.set_index('id'), on='id', rsuffix=f'_{label}')\n",
    "\n",
    "        # Save the resulting key and value dataframes to CSV files\n",
    "        df_key.to_csv(self.output_key_file, sep=';', index=False)\n",
    "        df_valor.to_csv(self.output_value_file, sep=';', index=False)\n",
    "\n",
    "# Main method to run the program\n",
    "def main():\n",
    "    # Create processor for human capital data, process it, and save results\n",
    "    processor = AnomalyScoreProcessor('data/humanNet.csv', 'data/key_human.csv', 'data/value_human.csv')\n",
    "    processor.process_scores()\n",
    "\n",
    "    # Create processor for social capital data, process it, and save results\n",
    "    processor = AnomalyScoreProcessor('data/socialNet.csv', 'data/key_social.csv', 'data/value_social.csv')\n",
    "    processor.process_scores()\n",
    "\n",
    "    # Create processor for mixed capital data, process it, and save results\n",
    "    processor = AnomalyScoreProcessor('data/mixedNet.csv', 'data/key_mixed.csv', 'data/value_mixed.csv')\n",
    "    processor.process_scores()\n",
    "    \n",
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # If so, run the main function\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a20dc1",
   "metadata": {},
   "source": [
    "# Documentation for Anomaly Score Processor\n",
    "\n",
    "This document provides a detailed explanation of the `AnomalyScoreProcessor` class and its associated methods for processing anomaly detection scores.\n",
    "\n",
    "## Table of Contents\n",
    "- [Overview](#overview)\n",
    "- [Class: `AnomalyScoreProcessor`](#class-anomalyscoreprocessor)\n",
    "  - [Method: `__init__`](#method-__init__)\n",
    "  - [Method: `_create_score_df`](#method-_create_score_df)\n",
    "  - [Method: `_create_anomaly_df`](#method-_create_anomaly_df)\n",
    "  - [Method: `process_scores`](#method-process_scores)\n",
    "- [Function: `main`](#function-main)\n",
    "- [Execution](#execution)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `AnomalyScoreProcessor` class is designed to process anomaly detection scores from a CSV file. It generates dataframes to store keys (sorted IDs by scores) and values (normalized scores) and outputs them as CSV files.\n",
    "\n",
    "---\n",
    "\n",
    "## Class: `AnomalyScoreProcessor`\n",
    "\n",
    "### Purpose:\n",
    "Processes anomaly detection scores and predictions to generate key-value dataframes for various models.\n",
    "\n",
    "### Attributes:\n",
    "- `data`: A Pandas DataFrame loaded from the input file.\n",
    "- `output_key_file`: Path for the output file containing sorted keys (IDs).\n",
    "- `output_value_file`: Path for the output file containing score values.\n",
    "\n",
    "---\n",
    "\n",
    "### Method: `__init__`\n",
    "\n",
    "#### Purpose:\n",
    "Initializes the processor by loading the input data and setting output file paths.\n",
    "\n",
    "#### Parameters:\n",
    "- `input_file` (str): Path to the input CSV file.\n",
    "- `output_key_file` (str): Path to save the key dataframe.\n",
    "- `output_value_file` (str): Path to save the value dataframe.\n",
    "\n",
    "---\n",
    "\n",
    "### Method: `_create_score_df`\n",
    "\n",
    "#### Purpose:\n",
    "Generates dataframes for a given score column.\n",
    "\n",
    "#### Parameters:\n",
    "- `score_col` (str): Name of the column containing the scores.\n",
    "- `label` (str): Label for the score type.\n",
    "\n",
    "#### Returns:\n",
    "- `df_key` (DataFrame): Dataframe containing sorted IDs as keys.\n",
    "- `df_valor` (DataFrame): Dataframe containing IDs and their corresponding scores.\n",
    "\n",
    "#### Details:\n",
    "- Sorts the IDs by their scores in descending order.\n",
    "- Creates a key dataframe with IDs and a value dataframe with the scores.\n",
    "\n",
    "---\n",
    "\n",
    "### Method: `_create_anomaly_df`\n",
    "\n",
    "#### Purpose:\n",
    "Processes anomaly predictions and scores to generate normalized dataframes.\n",
    "\n",
    "#### Parameters:\n",
    "- `pred_col` (str): Name of the column containing anomaly predictions.\n",
    "- `score_col` (str): Name of the column containing anomaly scores.\n",
    "- `label` (str): Label for the anomaly model.\n",
    "\n",
    "#### Returns:\n",
    "- `df_key` (DataFrame): Dataframe containing sorted IDs based on normalized scores.\n",
    "- `df_valor` (DataFrame): Dataframe containing IDs and their normalized scores.\n",
    "\n",
    "#### Details:\n",
    "- Maps anomalies (-1) to `1` and normal values (1) to `0`.\n",
    "- Assigns ranks to scores and normalizes them to create a consistent scale.\n",
    "\n",
    "---\n",
    "\n",
    "### Method: `process_scores`\n",
    "\n",
    "#### Purpose:\n",
    "Processes and combines multiple anomaly detection scores.\n",
    "\n",
    "#### Workflow:\n",
    "1. Processes scores for specific columns (`OS1`, `OS2`).\n",
    "2. Iterates through predefined anomaly models:\n",
    "   - `IsF`: Isolation Forest.\n",
    "   - `LOF`: Local Outlier Factor.\n",
    "   - `COV`: Covariance Estimator.\n",
    "   - `SVM`: Support Vector Machine.\n",
    "3. Combines dataframes for all models.\n",
    "4. Outputs the combined results to CSV files.\n",
    "\n",
    "#### Output:\n",
    "- Saves `df_key` and `df_valor` as CSV files.\n",
    "\n",
    "---\n",
    "\n",
    "## Function: `main`\n",
    "\n",
    "#### Purpose:\n",
    "Executes the anomaly score processing for different datasets.\n",
    "\n",
    "#### Workflow:\n",
    "1. Processes human capital data from `data/humanNet.csv`.\n",
    "2. Processes social capital data from `data/socialNet.csv`.\n",
    "3. Processes mixed capital data from `data/mixedNet.csv`.\n",
    "\n",
    "#### Output:\n",
    "- Generates key and value CSV files for each dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## Execution\n",
    "\n",
    "The script checks if it is run directly using the `if __name__ == \"__main__\":` condition. When executed, the `main` function is called to process anomaly scores for different datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- **Input Format**: The input files must be CSVs with columns for IDs, predictions, and scores.\n",
    "- **Output Files**: The processed data is saved as `;`-separated CSVs for compatibility.\n",
    "- **Dependencies**: Requires `pandas` and `numpy` libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

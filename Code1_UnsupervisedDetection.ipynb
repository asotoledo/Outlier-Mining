{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d7b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.ensemble import IsolationForest  \n",
    "from sklearn.neighbors import LocalOutlierFactor  \n",
    "from sklearn.linear_model import SGDOneClassSVM  \n",
    "from sklearn.covariance import EllipticEnvelope  \n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "# Class definition for anomaly detection using different models\n",
    "class AnomalyDetection:\n",
    "    \n",
    "    # Initialize the class with file paths and contamination level\n",
    "    def __init__(self, input_file, output_file, contamination=0.164):\n",
    "        # Store input and output file paths as class attributes\n",
    "        self.input_file = input_file  \n",
    "        self.output_file = output_file  \n",
    "        self.contamination = contamination  # Proportion of outliers expected in the data\n",
    "        self.df = pd.read_csv(input_file, sep=';')  # Read input CSV file into a pandas DataFrame\n",
    "    \n",
    "    # Preprocess the data to exclude certain columns and normalize the rest\n",
    "    def preprocess_data(self, exclude_columns):\n",
    "        # Exclude specified columns that are not used in anomaly detection\n",
    "        columns = [c for c in self.df.columns if c not in exclude_columns]\n",
    "        X = self.df[columns]  # Subset the DataFrame with only selected columns\n",
    "        \n",
    "        # Normalize the data using StandardScaler (mean=0, variance=1)\n",
    "        scaler = StandardScaler()\n",
    "        X_normalized = scaler.fit_transform(X)  # Fit the scaler and transform the data\n",
    "        # Return normalized data as a DataFrame with the original column names\n",
    "        return pd.DataFrame(X_normalized, columns=X.columns)\n",
    "    \n",
    "    # Apply Isolation Forest for anomaly detection\n",
    "    def apply_isolation_forest(self, X_normalized):\n",
    "        # Create an Isolation Forest model with specified parameters\n",
    "        isf = IsolationForest(n_estimators=100, max_samples=len(X_normalized),\n",
    "                              contamination=self.contamination, random_state=42)\n",
    "        # Train the model on normalized data\n",
    "        isf.fit(X_normalized)\n",
    "        # Return the anomaly scores and predictions (-1 = anomaly, 1 = normal)\n",
    "        return isf.decision_function(X_normalized), isf.predict(X_normalized)\n",
    "    \n",
    "    # Apply Local Outlier Factor for anomaly detection\n",
    "    def apply_local_outlier_factor(self, X_normalized):\n",
    "        # Create a Local Outlier Factor model with specified parameters\n",
    "        lof = LocalOutlierFactor(n_neighbors=20, algorithm='auto', leaf_size=30,\n",
    "                                 metric='minkowski', p=2, contamination=self.contamination,\n",
    "                                 novelty=True)  # novelty=True allows predicting on new data\n",
    "        # Train the model on normalized data\n",
    "        lof.fit(X_normalized)\n",
    "        # Return the anomaly scores and predictions (-1 = anomaly, 1 = normal)\n",
    "        return lof.decision_function(X_normalized), lof.predict(X_normalized)\n",
    "    \n",
    "    # Apply Elliptic Envelope for anomaly detection\n",
    "    def apply_elliptic_envelope(self, X_normalized):\n",
    "        # Create an Elliptic Envelope model with specified parameters\n",
    "        cov = EllipticEnvelope(contamination=self.contamination, random_state=42)\n",
    "        # Train the model on normalized data\n",
    "        cov.fit(X_normalized)\n",
    "        # Return the anomaly scores and predictions (-1 = anomaly, 1 = normal)\n",
    "        return cov.decision_function(X_normalized), cov.predict(X_normalized)\n",
    "    \n",
    "    # Apply One-Class SVM (Stochastic Gradient Descent) for anomaly detection\n",
    "    def apply_sgd_one_class_svm(self, X_normalized):\n",
    "        # Create a One-Class SVM model with specified parameters\n",
    "        svm = SGDOneClassSVM(nu=self.contamination, fit_intercept=True, max_iter=1000,\n",
    "                             tol=0.001, shuffle=True, verbose=0, random_state=42,\n",
    "                             learning_rate='optimal', eta0=0.0, power_t=0.5,\n",
    "                             warm_start=False, average=False)\n",
    "        # Train the model on normalized data\n",
    "        svm.fit(X_normalized)\n",
    "        # Return the anomaly scores and predictions (-1 = anomaly, 1 = normal)\n",
    "        return svm.decision_function(X_normalized), svm.predict(X_normalized)\n",
    "    \n",
    "    # Method to apply all anomaly detection models and store results\n",
    "    def detect_anomalies(self, exclude_columns):\n",
    "        # Step 1: Preprocess the data by excluding unnecessary columns and normalizing\n",
    "        X_normalized = self.preprocess_data(exclude_columns)\n",
    "        \n",
    "        # Step 2: Initialize a DataFrame to store the results, starting with 'id' column\n",
    "        df_results = pd.DataFrame(self.df['id'])\n",
    "        \n",
    "        # Step 3: Apply Isolation Forest and store the scores and predictions\n",
    "        scores_isf, y_pred_isf = self.apply_isolation_forest(X_normalized)\n",
    "        df_results['scores-IsF'] = scores_isf  # Store anomaly scores\n",
    "        df_results['anomaly-IsF'] = y_pred_isf  # Store anomaly predictions\n",
    "        \n",
    "        # Step 4: Apply Local Outlier Factor and store the scores and predictions\n",
    "        scores_lof, y_pred_lof = self.apply_local_outlier_factor(X_normalized)\n",
    "        df_results['scores-Lof'] = scores_lof  # Store anomaly scores\n",
    "        df_results['anomaly-Lof'] = y_pred_lof  # Store anomaly predictions\n",
    "        \n",
    "        # Step 5: Apply Elliptic Envelope and store the scores and predictions\n",
    "        scores_cov, y_pred_cov = self.apply_elliptic_envelope(X_normalized)\n",
    "        df_results['scores-Cov'] = scores_cov  # Store anomaly scores\n",
    "        df_results['anomaly-Cov'] = y_pred_cov  # Store anomaly predictions\n",
    "        \n",
    "        # Step 6: Apply One-Class SVM and store the scores and predictions\n",
    "        scores_svm, y_pred_svm = self.apply_sgd_one_class_svm(X_normalized)\n",
    "        df_results['scores-SVM'] = scores_svm  # Store anomaly scores\n",
    "        df_results['anomaly-SVM'] = y_pred_svm  # Store anomaly predictions\n",
    "        \n",
    "        # Step 7: Save the resulting DataFrame with all scores and predictions to the output file\n",
    "        df_results.to_csv(self.output_file, sep=';', index=False)\n",
    "        \n",
    "        # Optionally, the results can be returned (commented out)\n",
    "        # return df_results\n",
    "\n",
    "# Main function to run the anomaly detection for different strategies\n",
    "def main():\n",
    "    # Step 1: Specify the input file and output files for human, social, and mixed capital strategies\n",
    "    input_file = 'data/individuals.csv'\n",
    "    output_file_humano = 'data/human.csv'\n",
    "    output_file_social = 'data/social.csv'\n",
    "    output_file_misto = 'data/mixed.csv'\n",
    "    \n",
    "    # Step 2: Run anomaly detection for human capital data\n",
    "    anomaly_detector_humano = AnomalyDetection(input_file, output_file_humano)\n",
    "    # Exclude columns that are specific to human capital when detecting anomalies\n",
    "    anomaly_detector_humano.detect_anomalies(['id', 'Dc', 'Bc', 'Cc', 'CC', 'M'])\n",
    "    \n",
    "    # Step 3: Run anomaly detection for social capital data\n",
    "    anomaly_detector_social = AnomalyDetection(input_file, output_file_social)\n",
    "    # Exclude columns that are specific to social capital when detecting anomalies\n",
    "    anomaly_detector_social.detect_anomalies(['id', 'nickname', 'gender', 'skin', 'hair', 'height', 'tattoo', \n",
    "                                              'age', 'weapon', 'arrested', 'convicted', 'rape', 'extortion', \n",
    "                                              'kidnapping', 'theft', 'homicide', 'arms_trafficking', 'drug_trafficking', \n",
    "                                              'faction'])\n",
    "    \n",
    "    # Step 4: Run anomaly detection for mixed capital data\n",
    "    anomaly_detector_misto = AnomalyDetection(input_file, output_file_misto)\n",
    "    # Exclude only the 'id' column for mixed capital data when detecting anomalies\n",
    "    anomaly_detector_misto.detect_anomalies(['id'])\n",
    "\n",
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # If so, run the main function\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad58a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
